{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library, create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from module.layers.Dense import Dense\n",
    "from module.optimizer.Adam import Adam\n",
    "from module.layers.RNN import RNN\n",
    "from tensorflow import keras\n",
    "from module.Sequential import Sequential\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./dataset/DanhgiaSmartphone.csv\")\n",
    "data = df[[\"comment\", \"label\"]].values\n",
    "np.random.shuffle(data)\n",
    "print(len(data)) # 113\n",
    "train_data = data[:63]\n",
    "test_data = data[:63]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build word embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 6, 10)\n",
      "(63, 3)\n"
     ]
    }
   ],
   "source": [
    "# Hàm lấy word embedding cho 1 từ\n",
    "# get embedding vector for a word\n",
    "def get_wv(w):\n",
    "    try:\n",
    "        return w2v.wv[w]\n",
    "    except KeyError:\n",
    "        return w2v.wv[\"UNK\"]\n",
    "\n",
    "# Hàm tạo word embedding cho 1 tập dữ liệu \n",
    "# Get get embedding vector for the dataset\n",
    "def word_embedding(sentences):\n",
    "    sen_split = [[word for word in sen.lower().split()]for sen in sentences]\n",
    "    x = []\n",
    "    for s in sen_split:\n",
    "        v = []\n",
    "        for w in s:\n",
    "            v.append(get_wv(w))\n",
    "        x.append(v)\n",
    "    x = keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", dtype=\"float32\")\n",
    "    return x\n",
    "\n",
    "\"\"\" # Train word embedding model use Word2Vec\n",
    "df = pd.read_csv(\"./dataset/Train.csv\")\n",
    "sen_embedding = df[\"comment\"]\n",
    "\n",
    "# Xóa dấu câu và số trong dataset dùng để xây dựng word embedding\n",
    "# Remove special characters and digit\n",
    "sen_embedding_clean = []\n",
    "for sen in sen_embedding:\n",
    "    clean_sen = re.sub(r'[^\\w\\s]', '', sen)\n",
    "    clean_sen = re.sub(r'\\d', '', clean_sen)\n",
    "    sen_embedding_clean.append(clean_sen)\n",
    "\n",
    "sen_embedding_clean = [[word for word in sen.lower().split()] for sen in sen_embedding_clean]\n",
    "w2v = Word2Vec(sen_embedding_clean, vector_size=10)\n",
    "unk_vector = np.random.randn(10)\n",
    "w2v.wv.add_vector(\"UNK\", unk_vector)\n",
    "w2v.save(\"test.model\")  \"\"\"\n",
    "w2v = Word2Vec.load(\"test.model\")\n",
    "\n",
    "x_train = word_embedding(train_data[:, 0])\n",
    "y_train = OneHotEncoder(sparse_output=False).fit_transform(train_data[:, 1].reshape(-1, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  [==========]  loss: 0.3644, accuracy 36.51%\n",
      "Epoch 1  [==========]  loss: 0.3609, accuracy 52.38%\n",
      "Epoch 2  [==========]  loss: 0.3522, accuracy 55.56%\n",
      "Epoch 3  [==========]  loss: 0.3340, accuracy 57.14%\n",
      "Epoch 4  [==========]  loss: 0.3099, accuracy 53.97%\n",
      "Epoch 5  [==========]  loss: 0.2838, accuracy 53.97%\n",
      "Epoch 6  [==========]  loss: 0.2627, accuracy 58.73%\n",
      "Epoch 7  [==========]  loss: 0.2400, accuracy 60.32%\n",
      "Epoch 8  [==========]  loss: 0.2217, accuracy 63.49%\n",
      "Epoch 9  [==========]  loss: 0.2066, accuracy 66.67%\n",
      "Epoch 10 [==========]  loss: 0.1894, accuracy 74.60%\n",
      "Epoch 11 [==========]  loss: 0.1742, accuracy 76.19%\n",
      "Epoch 12 [==========]  loss: 0.1596, accuracy 77.78%\n",
      "Epoch 13 [==========]  loss: 0.1532, accuracy 77.78%\n",
      "Epoch 14 [==========]  loss: 0.1397, accuracy 82.54%\n",
      "Epoch 15 [==========]  loss: 0.1297, accuracy 82.54%\n",
      "Epoch 16 [==========]  loss: 0.1117, accuracy 90.48%\n",
      "Epoch 17 [==========]  loss: 0.0978, accuracy 92.06%\n",
      "Epoch 18 [==========]  loss: 0.0818, accuracy 92.06%\n",
      "Epoch 19 [==========]  loss: 0.0732, accuracy 95.24%\n"
     ]
    }
   ],
   "source": [
    "md = Sequential()\n",
    "md.add(RNN(32, active=\"relu\"))\n",
    "md.add(Dense(3, active=\"softmax\"))\n",
    "md.compile(optimizer=Adam(lr=0.003, beta1=0.9, beta2=0.99999))\n",
    "md.fit(X=x_train, y=y_train, batch_size=6, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "x_test = word_embedding(test_data[:, 0])\n",
    "y_test = OneHotEncoder(sparse_output=False).fit_transform(test_data[:, 1].reshape(-1, 1))\n",
    "pre, score = md.evalute(x_test, y_test)\n",
    "print(f\"Test accuracy: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
